"""
Multilingual Streaming TTS Example
Demonstrates streaming TTS for multiple languages including Persian, Arabic, French, etc.
"""
import torchaudio as ta
import torch
from chatterbox import ChatterboxMultilingualStreamingTTS, SUPPORTED_LANGUAGES

# Example texts for different languages
LANGUAGE_SAMPLES = {
    "fa": "ÿ≥ŸÑÿßŸÖÿå ŸÖŸÜ €å⁄© ŸÖÿØŸÑ ÿ™ÿ®ÿØ€åŸÑ ŸÖÿ™ŸÜ ÿ®Ÿá ⁄ØŸÅÿ™ÿßÿ± Ÿáÿ≥ÿ™ŸÖ ⁄©Ÿá ÿßÿ≤ ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å ŸÖ€å‚Äå⁄©ŸÜÿØ.",
    "ar": "ŸÖÿ±ÿ≠ÿ®ÿßÿå ÿ£ŸÜÿß ŸÜŸÖŸàÿ∞ÿ¨ ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ŸäÿØÿπŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©.",
    "en": "Hello, I am a text-to-speech model that supports the English language.",
    "fr": "Bonjour, je suis un mod√®le de synth√®se vocale qui prend en charge la langue fran√ßaise.",
    "de": "Hallo, ich bin ein Text-to-Speech-Modell, das die deutsche Sprache unterst√ºtzt.",
    "es": "Hola, soy un modelo de texto a voz que admite el idioma espa√±ol.",
    "zh": "‰Ω†Â•ΩÔºåÊàëÊòØ‰∏Ä‰∏™ÊîØÊåÅ‰∏≠ÊñáÁöÑÊñáÊú¨ËΩ¨ËØ≠Èü≥Ê®°Âûã„ÄÇ",
    "ja": "„Åì„Çì„Å´„Å°„ÅØ„ÄÅÁßÅ„ÅØÊó•Êú¨Ë™û„Çí„Çµ„Éù„Éº„Éà„Åô„Çã„ÉÜ„Ç≠„Çπ„ÉàË™≠„Åø‰∏ä„Åí„É¢„Éá„É´„Åß„Åô„ÄÇ",
    "ko": "ÏïàÎÖïÌïòÏÑ∏Ïöî, Ï†ÄÎäî ÌïúÍµ≠Ïñ¥Î•º ÏßÄÏõêÌïòÎäî ÌÖçÏä§Ìä∏ ÏùåÏÑ± Î≥ÄÌôò Î™®Îç∏ÏûÖÎãàÎã§.",
    "ru": "–ü—Ä–∏–≤–µ—Ç, —è –º–æ–¥–µ–ª—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫.",
    "tr": "Merhaba, ben T√ºrk√ße dilini destekleyen bir metin okuma modeliyim.",
    "hi": "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü-‡§ü‡•Ç-‡§∏‡•ç‡§™‡•Ä‡§ö ‡§Æ‡•â‡§°‡§≤ ‡§π‡•Ç‡§Ç ‡§ú‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§",
}


def main():
    # Automatically detect the best available device
    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = "mps"
    else:
        device = "cpu"

    print(f"üöÄ Using device: {device}")
    print("\nüåç Supported Languages:")
    for code, name in sorted(SUPPORTED_LANGUAGES.items()):
        print(f"   {code}: {name}")
    
    print("\nüì• Loading multilingual streaming model...")
    model = ChatterboxMultilingualStreamingTTS.from_pretrained(device=device)
    print("‚úÖ Model loaded successfully!")

    # Select languages to generate
    languages_to_test = ["fa", "ar", "en", "fr"]  # Persian, Arabic, English, French
    
    for lang_id in languages_to_test:
        if lang_id not in LANGUAGE_SAMPLES:
            print(f"‚ö†Ô∏è No sample text for language: {lang_id}")
            continue
            
        text = LANGUAGE_SAMPLES[lang_id]
        lang_name = SUPPORTED_LANGUAGES.get(lang_id, lang_id)
        
        print(f"\n{'='*60}")
        print(f"üåê Generating: {lang_name} ({lang_id})")
        print(f"üìù Text: {text[:50]}..." if len(text) > 50 else f"üìù Text: {text}")
        
        # Streaming generation
        streamed_chunks = []
        try:
            for audio_chunk, metrics in model.generate_stream(
                text=text,
                language_id=lang_id,
                chunk_size=25,
                exaggeration=0.5,
                temperature=0.8,
                cfg_weight=0.5,
                print_metrics=False  # Quiet mode for batch processing
            ):
                streamed_chunks.append(audio_chunk)
                
        except Exception as e:
            print(f"‚ùå Error generating {lang_name}: {e}")
            continue

        # Save audio
        if streamed_chunks:
            full_audio = torch.cat(streamed_chunks, dim=-1)
            output_file = f"output_{lang_id}.wav"
            ta.save(output_file, full_audio, model.sr)
            duration = full_audio.shape[-1] / model.sr
            print(f"‚úÖ Saved: {output_file} ({duration:.2f}s, {len(streamed_chunks)} chunks)")

    print(f"\n{'='*60}")
    print("üéâ MULTILINGUAL STREAMING DEMO COMPLETE!")


if __name__ == "__main__":
    main()

